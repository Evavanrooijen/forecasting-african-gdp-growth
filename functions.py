# -*- coding: utf-8 -*-
"""functions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WlIHSm2eGQnd7JrjuVWNGZ_M14onwfb7
"""

import time

import numpy as np
import pandas as pd
from math import sqrt
import matplotlib.pyplot as plt

import statsmodels.api as sm
import statsmodels.stats as stats
from scipy.stats import pearsonr
from lmfit import Parameters, minimize # package to apply NLS
from statsmodels.tsa.arima_model import ARIMA
from sklearn.metrics import mean_squared_error

# set seed for reproducibility
np.random.seed(1)

def growth_rate(x, steps=1):
    """ calculates first differences"""
    return x[steps:]-x[:-steps]

def create_DGP(N, T, alpha, var_eps):
  """ Function that takes all parameters and returns a simulated dataset [NxT]"""
  Y=np.random.rand(N, T)
  for i in range(N):
    Y[i, 0]=0
    theta = np.random.uniform(1, alpha, 1)
    for t in range(1, T):
      epsilon = np.random.normal(0, sqrt(var_eps), 1)
      Y[i, t]=theta+Y[i, t-1]+epsilon

  # unit tests for simulating DGP
  assert np.mean(Y, axis = 0)[0] == 0 # start time series 0 at t=0
  return Y

"""This function tests for cointegration
          Args:
            i (int): index of the country we are modeling
            tao (float): critical value (default = 0.4)

          Returns:
            JH (array): An array with the regressors (incl. self)
"""
def CRDW(Y, i, tao):
    """ find cointegrating countries """
    N, T = Y.shape
    JH = Y[i][1:-1]
    for j in range(N):
        if j!=i:
            y = Y[i]
            x = Y[j]
            x = sm.add_constant(x)
            model = sm.OLS(y, x)
            results = model.fit()
            CRDW_j = stats.stattools.durbin_watson(results.resid)
            if CRDW_j > tao:
                JH = np.vstack((JH, Y[j][1:-1]))
    assert JH.shape[0]>0

    return JH

def max_min_correlations(Y, i, kn=4, kp=4):
    """Feature selection based on pairwise correlation
    Args:
        Y_growth (array): matrix of levels (Y_growth)
        i (int): index of the country we are modeling
        tao (float): critical value (default = 0.4)

    Returns:
        JH (array): An array with the regressors (incl. self)

    """
    N, T = Y.shape
    Y_growth = np.vstack([growth_rate(row) for row in Y])


    corr_i = np.zeros(N)
    for j in range(N):
      corr_i[j] = pearsonr(Y_growth[i], Y_growth[j])[0]

    pos = Y_growth[np.argpartition(corr_i, -(kp+1))[-(kp+1):-1]]
    pos = pos[:, :-1]
    #pos = Y_growth[corr_i.argsort()[(kp+1):-1]]
    assert pos.shape == (kp, T-2)
    neg = Y_growth[corr_i.argsort()[:kn]]
    neg = neg[:, :-1]
    assert neg.shape == (kn, T-2)
    #neg = Y_growth[np.argpartition(correlation(7), -5)[-5:-1]]
    self_gr = Y_growth[i][:-1]
    return pos, neg, self_gr

def rolling_training(T1_size, t, rank, JH, pos, neg, self_gr):
  if rank > 1:
    JH_T1 = JH[:, t:t+T1_size]
  else:
    JH_T1 = JH[t:T1_size+t]
  pos_T1 = pos[:, t:t+T1_size]
  neg_T1 = neg[:, t:t+T1_size]
  self_T1 = self_gr[t:T1_size+t]

  assert pos_T1.shape[0] == 4
  assert pos_T1.shape[1] == T1_size
  return JH_T1, pos_T1, neg_T1, self_T1

def rolling_test(T1_size, t, rank, JH, pos, neg, self_gr):
  if rank > 1:
    JH_T2 = JH[:, t+T1_size]
  else:
    JH_T2 = JH[T1_size+t]
  pos_T2 = pos[:, t+T1_size]
  neg_T2 = neg[:, t+T1_size]
  self_T2 = self_gr[T1_size+t]

  assert pos_T2.size == 4
  return JH_T2, pos_T2, neg_T2, self_T2

def define_parameters(Y, i, tao):
  JH = CRDW(Y, i, tao)
  pos, neg, self_gr = max_min_correlations(Y, i)

  params = Parameters()
  rank = JH.shape[0]
  if rank == Y.shape[1]-2:
    rank = 1 #check this
  for r in range(1, rank):
    params.add('beta'+str(r), value = np.random.normal(-1, 1), max=0)


  params.add('mu', value = np.random.normal(0, 1))
  params.add('alpha_self', value = np.random.normal(0, 1))
  params.add('alpha_pos', value = np.random.normal(0, 1))
  params.add('alpha_neg', value = np.random.normal(0, 1))
  params.add('theta_pos', value = np.random.normal(0, 1))
  params.add('theta_neg', value = np.random.normal(0, 1))
  params.add('gamma', value = np.random.normal(0, 1))

  return JH, pos, neg, self_gr, params, rank

def run_simulation(Y,a, tao):
  N = Y.shape[0]
  T = Y.shape[1]
  T1_size = int((T*a)/(1+a))

  RMSPE = np.zeros(N)
  RMSPE_IMA = np.zeros(N)
  beaten = 0

  for i in range(N):

    predictions = np.zeros(T-T1_size-2)
    predictions_IMA = np.zeros(T-T1_size-2)
    truth = growth_rate(Y[i])[T1_size+1:] # to check

    assert truth.size == T-T1_size-2
    assert predictions.size == T-T1_size-2
    assert predictions_IMA.size == T-T1_size-2

    JH, pos, neg, self_gr, params, rank = define_parameters(Y, i, tao)

    for t in range(T-T1_size-2):
      #print(t)
      JH_T1, pos_T1, neg_T1, self_T1 = rolling_training(T1_size, t, rank, JH, pos, neg, self_gr)
      out = minimize(residual, params, args=(pos, neg, self_gr, JH, rank), method='leastsq', maxfev=2000000)
      fittedParams = out.params
      JH_T2, pos_T2, neg_T2, self_T2 = rolling_test(T1_size, t, rank, JH, pos, neg, self_gr)

      predictions[t] = step_forecast(pos_T2, neg_T2, JH_T2, self_T2, rank, fittedParams)

      model = ARIMA(growth_rate(Y[i])[t:T1_size+t], order=(0,1,1))
      model_fit = model.fit(disp=0)
      predictions_IMA[t] = model_fit.forecast(steps=1)[0] # Check the other scalar and 1x2 returned arrays

    RMSPE_i = calculate_RMSPE(predictions, truth)
    RMSPE_IMA_i = calculate_RMSPE(predictions_IMA, truth)
    #print('Hello!')
    if RMSPE_i>RMSPE_IMA_i:
        #print('Hello! We lost....')
        beaten += 1

  return beaten

def calculate_RMSPE(pred, truth):
  return sqrt(abs(np.mean((pred-truth)/truth))) #check this (abs) with franses!

def step_forecast(pos_T2, neg_T2, JH_T2, self_T2, rank, params):
  """calculates one-step ahead forecast """
  beta = np.ones(rank)
  for r in range(1, rank):
    beta[r] = params['beta'+str(r)].value

  mu = params['mu'].value
  gamma = params['gamma'].value
  alpha_self = params['alpha_self'].value
  alpha_pos = params['alpha_pos'].value
  alpha_neg = params['alpha_neg'].value
  theta_pos = params['theta_pos'].value
  theta_neg = params['theta_neg'].value

  assert beta[0] == 1
  assert np.sum(beta>0) == 1
  assert beta.size == rank

  alpha_i_j_p = np.array([alpha_pos, alpha_pos*theta_pos, alpha_pos*(theta_pos**2), alpha_pos*(theta_pos**3)])
  alpha_i_j_n = np.array([alpha_neg, alpha_neg*theta_neg, alpha_neg*(theta_neg**2), alpha_neg*(theta_neg**3)])

  assert alpha_i_j_p.size == 4
  assert alpha_i_j_n.size == 4
  assert pos_T2.size == 4

  #correlation = alpha_self * self_T2 + alpha_i_j_n.dot(neg_T2) + alpha_i_j_p.dot(pos_T2)
  correlation = alpha_i_j_n.dot(neg_T2) + alpha_i_j_p.dot(pos_T2)
  if rank == 1:
      cointegration = gamma * np.multiply(1, JH_T2) # check later
  else:
      cointegration = gamma * (beta.dot(JH_T2))
  output = cointegration + correlation + mu

  return output

def residual(params, pos, neg, self_gr, JH, rank):
  mu = params['mu']
  alpha_self = params['alpha_self']
  alpha_pos = params['alpha_pos']
  alpha_neg = params['alpha_neg']
  theta_pos = params['theta_pos']
  theta_neg = params['theta_neg']
  gamma = params['gamma']

  beta = np.ones(rank)
  for r in range(1, rank):
    beta[r] = params['beta'+str(r)]

  assert beta[0] == 1
  assert np.sum(beta>0) == 1
  assert beta.size == rank

  alpha_i_j_p = np.array([alpha_pos, alpha_pos*theta_pos, alpha_pos*(theta_pos**2), alpha_pos*(theta_pos**3)])
  alpha_i_j_n = np.array([alpha_neg, alpha_neg*theta_neg, alpha_neg*(theta_neg**2), alpha_neg*(theta_neg**3)])

  assert alpha_i_j_p.size == 4
  assert alpha_i_j_n.size == 4

  # TO-DO growth rate t-1, alpha_self ??
  #correlation = alpha_self * self_T1 + alpha_i_j_n.dot(neg_T1) + alpha_i_j_p.dot(pos_T1)
  correlation = alpha_i_j_n.dot(neg) + alpha_i_j_p.dot(pos)
  if rank == 1:
      cointegration = gamma * (np.multiply(beta, JH))
  else:
      cointegration = gamma * (beta.dot(JH))

  model = cointegration + correlation + mu

  return self_gr - model

"""only for visualization purposes"""
def run_single_simulation(Y,i, a, tao):
  N = Y.shape[0]
  T = Y.shape[1]
  T1_size = int((T*a)/(1+a))

  RMSPE = np.zeros(N)
  RMSPE_IMA = np.zeros(N)
  beaten = 0

  predictions = np.zeros(T-T1_size-2)
  predictions_IMA = np.zeros(T-T1_size-2)
  truth = growth_rate(Y[i])[T1_size+1:] # to check

  assert truth.size == predictions.size
  assert predictions_IMA.size == T-T1_size-2

  JH, pos, neg, self_gr, params, rank = define_parameters(Y, i, tao)

  for t in range(T-T1_size-2):
      JH_T1, pos_T1, neg_T1, self_T1 = rolling_training(T1_size, t, rank, JH, pos, neg, self_gr)
      assert pos_T1.shape[1] == T1_size
      out = minimize(residual, params, args=(pos_T1, neg_T1, self_T1, JH_T1, rank), method='leastsq', maxfev=2000000)
      fittedParams = out.params
      JH_T2, pos_T2, neg_T2, self_T2 = rolling_test(T1_size, t, rank, JH, pos, neg, self_gr)

      predictions[t] = step_forecast(pos_T2, neg_T2, JH_T2, self_T2, rank, fittedParams)

      model = ARIMA(growth_rate(Y[i])[t:T1_size+t], order=(0,1,1))
      model_fit = model.fit(disp=0)
      predictions_IMA[t] = model_fit.forecast(steps=1)[0] # Check the other scalar and 1x2 returned arrays

  RMSPE_i = calculate_RMSPE(predictions, truth)
  RMSPE_IMA_i = calculate_RMSPE(predictions_IMA, truth)

  if RMSPE_i>RMSPE_IMA_i:
      beaten += 1

  return beaten, predictions, predictions_IMA, truth, fittedParams, params, rank, JH, pos, neg
"""
def run_single_estimation2(Y, i, t, 2):
  N = Y.shape[0]
  T = Y.shape[1]
  T1_size = int((T*a)/(1+a))

  RMSPE = np.zeros(N)
  RMSPE_IMA = np.zeros(N)
  beaten = 0

  predictions = np.zeros(T-T1_size-2)
  predictions_IMA = np.zeros(T-T1_size-2)
  truth = growth_rate(Y[i])[T1_size+1:] # to check

  JH, pos, neg, self_gr, params, rank = define_parameters(Y, i)
  JH_T1, pos_T1, neg_T1, self_T1 = rolling_training(T1_size, t, rank, JH, pos, neg, self_gr)
  out = minimize(residual, params, args=(pos_T1, neg_T1, self_T1, JH_T1, rank), method='leastsq', maxfev=1000000)
  params = out.params

  beta = np.ones(rank)
  for r in range(1, rank):
    beta[r] = params['beta'+str(r)].value

  mu = params['mu'].value
  gamma = params['gamma'].value
  alpha_self = params['alpha_self'].value
  alpha_pos = params['alpha_pos'].value
  alpha_neg = params['alpha_neg'].value
  theta_pos = params['theta_pos'].value
  theta_neg = params['theta_neg'].value

  alpha_i_j_p = np.array([alpha_pos, alpha_pos*theta_pos, alpha_pos*(theta_pos**2), alpha_pos*(theta_pos**3)])
  alpha_i_j_n = np.array([alpha_neg, alpha_neg*theta_neg, alpha_neg*(theta_neg**2), alpha_neg*(theta_neg**3)])

  # TO-DO growth rate t-1, alpha_self ??
  correlation = alpha_self * self_T1 + alpha_i_j_n.dot(neg_T1) + alpha_i_j_p.dot(pos_T1)

  if rank == 1:
      cointegration = gamma * (np.multiply(beta, JH_T1)) #np.sum(JH_T1)
  else:
      cointegration = gamma * (beta.dot(JH_T1))

  output = cointegration + correlation + mu

  return output
"""
def plot_two_series(serie1, serie2, figureTitle=None, title1=None, title2=None):
  fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 3))
  fig.suptitle(figureTitle)
  axes[0].plot(serie1)
  axes[0].set_title(title1)
  axes[0].set_xlabel('t')
  axes[1].plot(serie2)
  axes[1].set_title(title2)
  axes[1].set_xlabel('t')
  fig.tight_layout()

def plot_resids(predictions, predictions_IMA, truth):
      fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 3))
      fig.suptitle("Residuals")
      axes[0].plot(predictions)
      axes[0].plot(truth)
      axes[0].set_title('RMSPE us: '+ str(calculate_RMSPE(predictions, truth)))
      axes[0].set_xlabel('t')
      axes[1].plot(predictions_IMA)
      axes[1].plot(truth)
      axes[1].set_title('RMSPE IMA: '+ str(calculate_RMSPE(predictions_IMA, truth)))
      axes[1].set_xlabel('t')
      fig.tight_layout()

"""
def exportResults(RMSPE_IMA, RMSPE_model, beaten):
    export = pd.DataFrame()

      # averages over sim_runs = 100, N countries
      export['RMSPE IMA'] = RMSPE_IMA
      export['RMSPE model'] = RMSPE_model
      export['beaten'] = beaten
      export['DGP Specification'] = None

      export.to_csv('Simulation Results.csv')
      print('File is exported')
"""
